{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab as pl\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from preprocess import *\n",
    "from collections import Counter\n",
    "import cv2\n",
    "from skimage.transform import pyramid_reduce\n",
    "from sklearn.metrics import accuracy_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n",
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "A = load_Dataset(\"../fonts-dataset/Scheherazade New/*.jpeg\")\n",
    "B= load_Dataset(\"../fonts-dataset/Lemonada/*.jpeg\")\n",
    "C= load_Dataset(\"../fonts-dataset/Marhey/*.jpeg\")\n",
    "D= load_Dataset(\"../fonts-dataset/IBM Plex Sans Arabic/*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, A_TEST = train_test_split(A, test_size=0.2)\n",
    "B, B_TEST = train_test_split(B, test_size=0.2)\n",
    "C, C_TEST = train_test_split(C, test_size=0.2)\n",
    "D, D_TEST = train_test_split(D, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  320\n",
      "B:  320\n",
      "C:  320\n",
      "D:  320\n"
     ]
    }
   ],
   "source": [
    "A_PROCESSED = []\n",
    "for img in A:\n",
    "    img=denoise(img)\n",
    "    A_PROCESSED.append(img)\n",
    "print(\"A: \", len(A_PROCESSED))\n",
    "B_PROCESSED = []\n",
    "for img in B:\n",
    "    img=denoise(img)\n",
    "    B_PROCESSED.append(img)\n",
    "print(\"B: \", len(B_PROCESSED))\n",
    "C_PROCESSED = []\n",
    "for img in C:\n",
    "    img=denoise(img)\n",
    "    C_PROCESSED.append(img)\n",
    "print(\"C: \", len(C_PROCESSED))\n",
    "D_PROCESSED = []\n",
    "for img in D:\n",
    "    img=denoise(img)\n",
    "    D_PROCESSED.append(img)\n",
    "print(\"D: \", len(D_PROCESSED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_level(image):\n",
    "    img=image.copy()\n",
    "    levels = []\n",
    "    while img.shape[0] > 64:\n",
    "        levels.append(img)\n",
    "        img = pyramid_reduce(img)\n",
    "    levels.append(img)\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_levels(images):\n",
    "    levels = []\n",
    "    for img in images:\n",
    "        levels.append(get_level(img))\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaussian_kernel(m=4):\n",
    "    x_index, y_index = np.meshgrid(np.arange(-m, m + 1), np.arange(-m, m + 1))\n",
    "    x_index = x_index.reshape((-1, 1))\n",
    "    y_index = y_index.reshape((-1, 1))\n",
    "\n",
    "    G = lambda x, y: np.exp(-(x**2 + y**2))\n",
    "    G0 = lambda x, y: -2*x*G(x,y)\n",
    "\n",
    "    # OPTIONAL: remove negative (to align mathematically) since vertical numers increase as we go down \n",
    "    G90 = lambda x, y: 2*y*G(x,y) \n",
    "\n",
    "    # Gaussian Kernel\n",
    "    gk = G(x_index, y_index).reshape((m*2 + 1, m*2 + 1))\n",
    "\n",
    "    # Gaussian 1st Deriviative with 0 degree orientation\n",
    "    gk0 = G0(x_index, y_index).reshape((m*2 + 1, m*2 + 1))\n",
    "\n",
    "    # Gaussian 1st Deriviative with 90 degree orientation\n",
    "    gk90 = G90(x_index, y_index).reshape((m*2 + 1, m*2 + 1))\n",
    "    return gk0, gk90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steering_filters(steering_angles,gk0,gk90):\n",
    "    gk_theta=[]\n",
    "    for angle in steering_angles:\n",
    "        gk_theta.append(np.cos(np.radians(angle))*gk0 + np.sin(np.radians(angle))*gk90)\n",
    "    return gk_theta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters_get_variance(levels,filters):\n",
    "    variances = []\n",
    "    for level in levels:\n",
    "        for filteri in filters:\n",
    "            filtered=cv2.filter2D(level, -1, filteri)\n",
    "            variances.append(np.var(filtered))\n",
    "    return variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "gk0, gk90 = get_gaussian_kernel()\n",
    "steering_angles = np.arange(0, 180, 30)\n",
    "gk_thetas = get_steering_filters(steering_angles, gk0, gk90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_levels=[]\n",
    "A_levels=(get_levels(A_PROCESSED))\n",
    "B_levels=[]\n",
    "B_levels=(get_levels(A_PROCESSED))\n",
    "C_levels=[]\n",
    "C_levels=(get_levels(A_PROCESSED))\n",
    "D_levels=[]\n",
    "D_levels=(get_levels(A_PROCESSED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Vars=[]\n",
    "for levels in A_levels:\n",
    "    A_Vars.append(apply_filters_get_variance(levels,gk_thetas))\n",
    "B_Vars=[]\n",
    "for levels in B_levels:\n",
    "    B_Vars.append(apply_filters_get_variance(levels,gk_thetas))\n",
    "C_Vars=[]\n",
    "for levels in C_levels:\n",
    "    C_Vars.append(apply_filters_get_variance(levels,gk_thetas))\n",
    "D_Vars=[]\n",
    "for levels in D_levels:\n",
    "    D_Vars.append(apply_filters_get_variance(levels,gk_thetas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=np.concatenate((np.zeros(len(A_Vars)),np.ones(len(B_Vars)),np.full(len(C_Vars),2),np.full(len(D_Vars),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list=A_Vars+B_Vars+C_Vars+D_Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn_classifier(k, train_features, train_labels):\n",
    "    # Create KNN classifier object\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k,n_jobs=-1,weights='distance',metric='euclidean',algorithm='auto')\n",
    "    \n",
    "    # Train the classifier\n",
    "    knn_classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    return knn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = train_knn_classifier(11,combined_list,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:  80\n",
      "B:  80\n",
      "C:  80\n",
      "D:  80\n"
     ]
    }
   ],
   "source": [
    "A_TLEVELS = []\n",
    "for img in A_TEST:\n",
    "    img=denoise(img)\n",
    "    A_TLEVELS.append(img)\n",
    "print(\"A: \", len(A_TLEVELS))\n",
    "B_TLEVELS = []\n",
    "for img in B_TEST:\n",
    "    img=denoise(img)\n",
    "    B_TLEVELS.append(img)\n",
    "print(\"B: \", len(B_TLEVELS))\n",
    "C_TLEVELS = []\n",
    "for img in C_TEST:\n",
    "    img=denoise(img)\n",
    "    C_TLEVELS.append(img)\n",
    "print(\"C: \", len(C_TLEVELS))\n",
    "D_TLEVELS = []\n",
    "for img in D_TEST:\n",
    "    img=denoise(img)\n",
    "    D_TLEVELS.append(img)\n",
    "print(\"D: \", len(D_TLEVELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_TLEVELS=get_levels(A_TLEVELS)\n",
    "B_TLEVELS=get_levels(B_TLEVELS)\n",
    "C_TLEVELS=get_levels(C_TLEVELS)\n",
    "D_TLEVELS=get_levels(D_TLEVELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_TVars=[]\n",
    "for levels in A_TLEVELS:\n",
    "    A_TVars.append(apply_filters_get_variance(levels,gk_thetas))\n",
    "B_TVars=[]\n",
    "for levels in B_TLEVELS:\n",
    "    B_TVars.append(apply_filters_get_variance(levels,gk_thetas))\n",
    "C_TVars=[]\n",
    "for levels in C_TLEVELS:\n",
    "    C_TVars.append(apply_filters_get_variance(levels,gk_thetas))\n",
    "D_TVars=[]\n",
    "for levels in D_TLEVELS:\n",
    "    D_TVars.append(apply_filters_get_variance(levels,gk_thetas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_test_list=A_TVars+B_TVars+C_TVars+D_TVars\n",
    "test_labels=np.concatenate((np.zeros(len(A_TVars)),np.ones(len(B_TVars)),np.full(len(C_TVars),2),np.full(len(D_TVars),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 24.0625\n"
     ]
    }
   ],
   "source": [
    "predictions = knn_classifier.predict(combined_test_list)\n",
    "accuracy = accuracy_score(test_labels, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
