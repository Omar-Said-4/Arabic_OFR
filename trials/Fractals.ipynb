{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab as pl\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_count(image, box_size):\n",
    "  \"\"\"\n",
    "  Counts the number of non-empty boxes of a specific size covering the image.\n",
    "\n",
    "  Args:\n",
    "    image: A 2D numpy array representing the binary image.\n",
    "    box_size: The size of the square boxes used for counting.\n",
    "\n",
    "  Returns:\n",
    "    The number of non-empty boxes.\n",
    "  \"\"\"\n",
    "  n_rows, n_cols = image.shape\n",
    "  n_boxes_x = int(n_cols // box_size)\n",
    "  n_boxes_y = int(n_rows // box_size)\n",
    "  count = 0\n",
    "  resized_image = image[:n_boxes_y * box_size, :n_boxes_x * box_size]\n",
    "    \n",
    "    # Reshape the resized image into boxes\n",
    "  boxes = resized_image.reshape(n_boxes_y, box_size, n_boxes_x, box_size)\n",
    "    \n",
    "    # Check if any pixel in each box is non-zero (foreground)\n",
    "  non_zero_boxes = np.any(boxes, axis=(1, 3))\n",
    "    \n",
    "    # Count the number of non-zero boxes\n",
    "  count = np.sum(non_zero_boxes)\n",
    "  return count\n",
    "def box_counting_dimension(image, min_size, max_size, scale_factor=2):\n",
    "  \"\"\"\n",
    "  Calculates the box counting dimension of a binary image.\n",
    "\n",
    "  Args:\n",
    "    image: A 2D numpy array representing the binary image.\n",
    "    min_size: The minimum size of the square boxes used for counting.\n",
    "    max_size: The maximum size of the square boxes used for counting.\n",
    "    scale_factor: The factor by which the box size is scaled at each iteration.\n",
    "\n",
    "  Returns:\n",
    "    The estimated box counting dimension.\n",
    "  \"\"\"\n",
    "  # Convert image to binary (foreground = 1, background = 0)\n",
    "  image = image > 0  \n",
    "\n",
    "  # Prepare lists to store box sizes and counts\n",
    "  box_sizes = []\n",
    "  box_counts = []\n",
    "  \n",
    "  # Iterate through different box sizes\n",
    "  box_size = min_size\n",
    "  while box_size <= max_size:\n",
    "    count = box_count(image, box_size)\n",
    "    box_sizes.append(box_size)\n",
    "    box_counts.append(count)\n",
    "    box_size *= scale_factor\n",
    "\n",
    "  # Fit a linear regression to log(box_size) vs log(box_count)\n",
    "  log_sizes = np.log(box_sizes)\n",
    "  log_counts = np.log(box_counts)\n",
    "  slope, _ = np.polyfit(log_sizes, log_counts, 1)\n",
    "  print (slope)\n",
    "  # Estimated box counting dimension is negative of the slope\n",
    "  return (slope-1*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "A = load_Dataset(\"../fonts-dataset/Scheherazade New/*.jpeg\")\n",
    "B= load_Dataset(\"../fonts-dataset/Lemonada/*.jpeg\")\n",
    "C= load_Dataset(\"../fonts-dataset/Marhey/*.jpeg\")\n",
    "D= load_Dataset(\"../fonts-dataset/IBM Plex Sans Arabic/*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_PROCESSED = []\n",
    "for img in A:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    A_PROCESSED.append(img)\n",
    "B_PROCESSED = []\n",
    "for img in B:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    B_PROCESSED.append(img)\n",
    "C_PROCESSED = []\n",
    "for img in C:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    C_PROCESSED.append(img)\n",
    "D_PROCESSED = []\n",
    "for img in D:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    D_PROCESSED.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A done\n",
      "B done\n",
      "C done\n",
      "D done\n"
     ]
    }
   ],
   "source": [
    "A_BCD=[]\n",
    "for img in A_PROCESSED:\n",
    "    A_BCD.append(box_counting_dimension(img,2,120))\n",
    "print(\"A done\")\n",
    "B_BCD=[]\n",
    "for img in B_PROCESSED:\n",
    "    B_BCD.append(box_counting_dimension(img,2,120))\n",
    "print(\"B done\")\n",
    "C_BCD=[]\n",
    "for img in C_PROCESSED:\n",
    "    C_BCD.append(box_counting_dimension(img,2,120))\n",
    "print(\"C done\")\n",
    "D_BCD=[]\n",
    "for img in D_PROCESSED:\n",
    "    D_BCD.append(box_counting_dimension(img,2,120))\n",
    "print(\"D done\")\n",
    "A_BCD=[result for result in A_BCD if not np.isnan(result)]\n",
    "B_BCD=[result for result in B_BCD if not np.isnan(result)]\n",
    "C_BCD=[result for result in C_BCD if not np.isnan(result)]\n",
    "D_BCD=[result for result in D_BCD if not np.isnan(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([A_BCD, B_BCD, C_BCD, D_BCD])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(A_BCD)), np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(B_BCD)), \n\u001b[0;32m      3\u001b[0m                     \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(C_BCD)), \u001b[38;5;241m3\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mlen\u001b[39m(D_BCD))])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m train_features, test_features, train_labels, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#print(labels)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m KNN \u001b[38;5;241m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2649\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2646\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2648\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2649\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_split.py:2305\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2302\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2309\u001b[0m     )\n\u001b[0;32m   2311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X = np.concatenate([A_BCD, B_BCD, C_BCD, D_BCD]).reshape(-1,1)\n",
    "y = np.concatenate([np.zeros(len(A_BCD)), np.ones(len(B_BCD)), \n",
    "                    2*np.ones(len(C_BCD)), 3*np.ones(len(D_BCD))]).reshape(-1,1)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=40)\n",
    "    \n",
    "    #print(labels)\n",
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "KNN.fit(train_features, train_labels)\n",
    "        \n",
    "    \n",
    "accuracy = KNN.score(test_features, test_labels)\n",
    "        \n",
    "print('accuracy: ', accuracy*100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
