{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hu Moments ( or rather Hu moment invariants ) are a set of 7 numbers calculated using central moments that are invariant to image transformations. The first 6 moments have been proved to be invariant to translation, scale, and rotation, and reflection. While the 7th momentâ€™s sign changes for image reflection.\n",
    "\n",
    "\n",
    "#### here we use images as it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#import cv2\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab as pl\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from preprocess import *\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import math\n",
    "from skimage.transform import pyramid_reduce\n",
    "from sklearn.metrics import accuracy_score\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n",
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "A = load_Dataset(\"../fonts-dataset/Scheherazade New/*.jpeg\")\n",
    "B= load_Dataset(\"../fonts-dataset/Lemonada/*.jpeg\")\n",
    "C= load_Dataset(\"../fonts-dataset/Marhey/*.jpeg\")\n",
    "D= load_Dataset(\"../fonts-dataset/IBM Plex Sans Arabic/*.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, A_TEST = train_test_split(A, test_size=0.2)\n",
    "B, B_TEST = train_test_split(B, test_size=0.2)\n",
    "C, C_TEST = train_test_split(C, test_size=0.2)\n",
    "D, D_TEST = train_test_split(D, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_PROCESSED = []\n",
    "for img in A:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    A_PROCESSED.append(img)\n",
    "B_PROCESSED = []\n",
    "for img in B:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    B_PROCESSED.append(img)\n",
    "C_PROCESSED = []\n",
    "for img in C:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    C_PROCESSED.append(img)\n",
    "D_PROCESSED = []\n",
    "for img in D:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    D_PROCESSED.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_moms=[]\n",
    "for im in A_PROCESSED:\n",
    "    moments = cv2.moments(im) \n",
    "    huMoments = cv2.HuMoments(moments)\n",
    "    huMoments = -np.sign(huMoments) * np.log10(np.abs(huMoments+0.001))\n",
    "    A_moms.append(huMoments.flatten())\n",
    "B_moms=[]\n",
    "for im in B_PROCESSED:\n",
    "    moments = cv2.moments(im) \n",
    "    huMoments = cv2.HuMoments(moments)\n",
    "    huMoments = -np.sign(huMoments) * np.log10(np.abs(huMoments+0.001))\n",
    "    B_moms.append(huMoments.flatten())\n",
    "C_moms=[]\n",
    "for im in C_PROCESSED:\n",
    "    moments = cv2.moments(im) \n",
    "    huMoments = cv2.HuMoments(moments)\n",
    "    huMoments = -np.sign(huMoments) * np.log10(np.abs(huMoments+0.001))\n",
    "    C_moms.append(huMoments.flatten())\n",
    "D_moms=[]\n",
    "for im in D_PROCESSED:\n",
    "    moments = cv2.moments(im) \n",
    "    huMoments = cv2.HuMoments(moments)\n",
    "    huMoments = -np.sign(huMoments) * np.log10(np.abs(huMoments+0.001))\n",
    "    D_moms.append(huMoments.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels=np.concatenate((np.zeros(len(A_moms)),np.ones(len(B_moms)),np.full(len(C_moms),2),np.full(len(D_moms),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list=A_moms+B_moms+C_moms+D_moms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn_classifier(k, train_features, train_labels):\n",
    "    # Create KNN classifier object\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=k,n_jobs=-1,weights='distance',metric='euclidean',algorithm='auto')\n",
    "    \n",
    "    # Train the classifier\n",
    "    knn_classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    return knn_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = train_knn_classifier(5,combined_list,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_TPROCESSED = []\n",
    "for img in A_TEST:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    A_TPROCESSED.append(img)\n",
    "B_TPROCESSED = []\n",
    "for img in B_TEST:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    B_TPROCESSED.append(img)\n",
    "C_TPROCESSED = []\n",
    "for img in C_TEST:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    C_TPROCESSED.append(img)\n",
    "D_TPROCESSED = []\n",
    "for img in D_TEST:\n",
    "    img = threshold_image(img)\n",
    "    img= assure_white_bg(img)\n",
    "    D_TPROCESSED.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_Tmoms=[]\n",
    "for im in A_TPROCESSED:\n",
    "        moments = cv2.moments(im) \n",
    "        huMoments = cv2.HuMoments(moments)\n",
    "        huMoments = -np.sign(huMoments) * np.log10(np.abs(huMoments+0.001))\n",
    "        A_Tmoms.append(huMoments.flatten())\n",
    "B_Tmoms=[]\n",
    "for im in B_TPROCESSED:\n",
    "        moments = cv2.moments(im) \n",
    "        huMoments = cv2.HuMoments(moments)\n",
    "        huMoments = -np.sign(huMoments) * np.log10(np.abs(huMoments+0.001))\n",
    "        B_Tmoms.append(huMoments.flatten())\n",
    "C_Tmoms=[]\n",
    "for im in C_TPROCESSED:\n",
    "        moments = cv2.moments(im) \n",
    "        huMoments = cv2.HuMoments(moments)\n",
    "        huMoments = -np.sign(huMoments) * np.log10(np.abs(huMoments+0.001))\n",
    "        C_Tmoms.append(huMoments.flatten())     \n",
    "D_Tmoms=[]\n",
    "for im in D_TPROCESSED:\n",
    "        moments = cv2.moments(im) \n",
    "        huMoments = cv2.HuMoments(moments)\n",
    "        huMoments = -np.sign(huMoments) * np.log10(np.abs(huMoments+0.001))\n",
    "        D_Tmoms.append(huMoments.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list_test=A_Tmoms+B_Tmoms+C_Tmoms+D_Tmoms\n",
    "test_labels=np.concatenate((np.zeros(len(A_Tmoms)),np.ones(len(B_Tmoms)),np.full(len(C_Tmoms),2),np.full(len(D_Tmoms),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.125\n"
     ]
    }
   ],
   "source": [
    "preds=knn_classifier.predict(combined_list_test)\n",
    "print(accuracy_score(test_labels,preds)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
